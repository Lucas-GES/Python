# -*- coding: utf-8 -*-
"""Big_Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FLxx9ErmPtOqW8nfWJQmPf2UKh088IYo
"""

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!apt-get install axel

!axel -n 10 https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz

!tar xf spark-2.4.4-bin-hadoop2.7.tgz

!pip install -q findspark

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-2.4.4-bin-hadoop2.7"

import findspark
findspark.init('spark-2.4.4-bin-hadoop2.7')

from pyspark.sql import SparkSession
sc = SparkSession.builder.master('local[*]').getOrCreate()

!wget --quiet --show-progress http://data.insideairbnb.com/brazil/rj/rio-de-janeiro/2021-07-17/data/listings.csv.gz

!gunzip listings.csv.gz

df_spark = sc.read.csv("./listings.csv", inferSchema=True, header=True)

df_spark.printSchema()

df_spark.toPandas().head()

# Análise Big Data ----------------------------

!wget -O viagens-2020.zip http://www.transparencia.gov.br/download-de-dados/viagens/2020

!apt install file

!unzip viagens-2020.zip

!iconv -f ISO8859-1 -t UTF-8 2020_Viagem.csv > 2020_Viagem_UTF8.csv

df = sc.read.csv('2020_Viagem_UTF8.csv', header=True, sep=';')

df.printSchema()

df.limit(5).toPandas()

#imports
from pyspark.sql import functions as F
from pyspark.sql.types import FloatType

def to_value(v):
  try:
    return float(v.replace(',', '.'))
  except Error:
    return 0.0

udf_to_value = F.udf(to_value, FloatType())

df_typed = df.withColumn("ValorPassagens", udf_to_value(df["Valor passagens"])) \
  .withColumn("ValorDiarias", udf_to_value(df["Valor diárias"])) \
  .withColumn("ValorOutros", udf_to_value(df["Valor outros gastos"]))

df_typed.limit(10).select("Nome órgão solicitante", "ValorPassagens").toPandas()

df_typed.groupBy("Nome do órgão superior") \
  .agg(F.sum("ValorPassagens").alias("Total")) \
  .orderBy("Total", ascending=False).toPandas()

pd = df_typed.groupBy("Nome do órgão superior").agg((F.sum("ValorPassagens") / 1000000).alias("Total")).orderBy("Total", ascending=False).toPandas()
pd

pd.plot(kind="barh", x="Nome do órgão superior", figsize=[12,8], width=0.9)

df_typed.groupBy("Nome", "CPF viajante").agg((F.sum("ValorPassagens") / 1e+3).alias("ValorTotal")).orderBy("ValorTotal", ascending=False).limit(10).toPandas()

df_typed.groupBy("Nome", "CPF viajante").agg((F.sum("ValorPassagens") / 1e+3).alias("ValorTotal")).filter("Nome != 'Informações protegidas por sigilo'").orderBy("ValorTotal", ascending=False).limit(10).toPandas()

df_typed.groupBy("Nome", "CPF viajante").agg(((F.sum("ValorPassagens") + F.sum("ValorDiarias") + F.sum("ValorOutros") ) / 1e+3).alias("ValorTotal")).filter("Nome != 'Informações protegidas por sigilo'").orderBy("ValorTotal", ascending=False).limit(10).toPandas()

df_typed.groupBy("Nome", "CPF viajante").agg(((F.sum("ValorPassagens") + F.sum("ValorDiarias") + F.sum("ValorOutros") ) / 1e+3).alias("ValorTotal"), F.count("ValorPassagens").alias("Número de viagens")).filter("Nome != 'Informações protegidas por sigilo'").orderBy("ValorTotal", ascending=False).limit(10).toPandas()

df_typed.groupBy("Nome", "Nome do órgão superior", "CPF viajante").agg(((F.sum("ValorPassagens") + F.sum("ValorDiarias") + F.sum("ValorOutros") ) / 1e+3).alias("ValorTotal"), F.count("ValorPassagens").alias("Número de vaigens")).filter("Nome != 'Informações protegidas por sigilo'").orderBy("ValorTotal", ascending=False).limit(10).toPandas()

df_typed.filter((df_typed["Nome"] == 'MARCOS ROSAS DEGAUT PONTES') & (df_typed["CPF Viajante"] == '***.874.611-**')).toPandas()

df_typed.filter((df_typed["Nome"] == 'MARCOS ROSAS DEGAUT PONTES') & (df_typed["CPF viajante"] == '***.874.611-**')).withColumn("dataPartida", F.to_date(df["Período - Data de início"], format="dd/MM/yyyy")).toPandas()

pd_gasto = df_typed.filter((df_typed["Nome"] == 'MARCOS ROSAS DEGAUT PONTES') & (df_typed["CPF viajante"] == '***.874.611-**')).withColumn("dataPartida", F.to_date(df["Período - Data de início"], format='dd/MM/yyyy')).groupBy(F.month("dataPartida").alias("mesPartida")).agg(((F.sum("ValorPassagens") + F.sum("ValorDiarias") + F.sum("ValorOutros") ) / 1e+3).alias("ValorTotal"), F.count("ValorPassagens").alias("Número de viagens")).orderBy("mesPartida").toPandas()

pd_gasto

pd_gasto.plot(x="mesPartida", figsize=[16, 8], xticks=range(1, 13))